{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a NEAT to learn defend_the_center.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from vizdoom import * #Import all of vizdoom\n",
    "import time #To make the program sleep (wait), so we can actually see what's happening\n",
    "from gymnasium import Env #Import OpenAI Gym's Env class\n",
    "from gymnasium.spaces import Discrete, Box #Import OpenAI Gym's Discrete and Box spaces\n",
    "import cv2 #OpenCV for image processing, used for modifying the DOOM environment to make it run faster \n",
    "from stable_baselines3.common.callbacks import BaseCallback #Import the BaseCallback class from stable_baselines3 to learn from the environment\n",
    "from stable_baselines3.common import env_checker #Import the env_checker class from stable_baselines3 to check the environment\n",
    "import os #To create directories for saving models\n",
    "import sys #To backtrack to root\n",
    "import neat\n",
    "\n",
    "original_sys_path = sys.path.copy() #Come back to this path later after we navigate to the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  #Add the parent directory to the path so we can import the pathfinder module\n",
    "from pathfinder import doomfinder, create_new_best_generation_directory, gamefinder #Import functions from the pathfinder module\n",
    "sys.path = original_sys_path #Set the path back to the original path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the VizDoom environment\n",
    "do_render = False\n",
    "episodes = 1\n",
    "\n",
    "class DefendTheCenterNEAT:\n",
    "    def __init__(self, config_path, render=False, episodes=1): \n",
    "        self.game = DoomGame()\n",
    "        self.game.set_doom_game_path(gamefinder('DOOM2.wad'))\n",
    "        self.game.load_config(config_path)\n",
    "        self.game.set_window_visible(render)\n",
    "        self.game.init()\n",
    "        self.ammo = 26  #Initial ammo \n",
    "        self.health = 100\n",
    "        self.killcount = 0\n",
    "\n",
    "    def set_params(self, do_render=False, episodes=1):\n",
    "        do_render = do_render\n",
    "        episodes = episodes\n",
    "\n",
    "    def get_observation(self):\n",
    "        state = self.game.get_state()\n",
    "        if state:\n",
    "            buffer = state.screen_buffer\n",
    "            grey = cv2.cvtColor(np.moveaxis(buffer, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grey, (40, 25), interpolation=cv2.INTER_CUBIC)\n",
    "            return resized.flatten()  #Flatten to 1000 elements for NEAT input\n",
    "        else:\n",
    "            return np.zeros(40 * 25)\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 6) #Observe action every 6 frames, action will be repeated for 6 frames\n",
    "        done = self.game.is_episode_finished()\n",
    "        return reward, done\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        return self.get_observation()\n",
    "\n",
    "def eval_genome(genomes, config):\n",
    "    #Initialize the environment\n",
    "    env = DefendTheCenterNEAT(doomfinder('defend_the_center_modified.cfg'), render=do_render, episodes=episodes)\n",
    "\n",
    "    #Evaluate each genome in the population\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        fitness = 0\n",
    "\n",
    "        for _ in range(episodes):  #Evaluate over 1 episode\n",
    "            obs = env.reset()\n",
    "            episode_fitness = 0\n",
    "            kill_reward = 0\n",
    "            ammo_wasted = 0\n",
    "\n",
    "            while not env.game.is_episode_finished():\n",
    "                got_kill = False #Flag to check if a kill was made\n",
    "\n",
    "                #Get action from NEAT network\n",
    "                output = net.activate(obs)  #obs is a flattened array (1000 elements)\n",
    "                action = np.argmax(output)\n",
    "                ammo, health, killcount = env.game.get_state().game_variables\n",
    "\n",
    "                #Take action\n",
    "                reward, done = env.step(action)\n",
    "                episode_fitness += reward\n",
    "\n",
    "                #Calculate ammo wasted\n",
    "                ammo_used = env.ammo - ammo\n",
    "                env.ammo = ammo\n",
    "                \n",
    "                env.health = health\n",
    "                if env.killcount < killcount:\n",
    "                    got_kill = True\n",
    "\n",
    "                env.killcount = killcount\n",
    "\n",
    "                if ammo_used > 0 and not got_kill: #If ammo was used and no kill was made\n",
    "                    ammo_wasted += ammo_used\n",
    "\n",
    "                if got_kill:    \n",
    "                    kill_reward += (1 + 1 * health/100) #Reward for getting a kill, scaled by health\n",
    "\n",
    "            #Penalize wasted ammo\n",
    "            ammo_delta = ammo_wasted * 0.1\n",
    "            kill_delta = kill_reward \n",
    "\n",
    "            episode_fitness = ammo_delta + kill_delta  \n",
    "\n",
    "            fitness += episode_fitness\n",
    "\n",
    "        #Assign fitness to the genome\n",
    "        genome.fitness = fitness / episodes  #Average fitness across episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_neat(config_path):\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_path)\n",
    "    \n",
    "    #Create population\n",
    "    population = neat.Population(config)\n",
    "\n",
    "    #Add reporters\n",
    "    population.add_reporter(neat.StdOutReporter(True))\n",
    "    population.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "    #Run evolution\n",
    "    winner = population.run(eval_genome)\n",
    "    #Save the best genome\n",
    "    torch.save(winner, \"best_neat_genome.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_neat(\"Maps and Configs/neat-config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_genome(config_path, genome_path):\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_path)\n",
    "    \n",
    "    #Load the best genome\n",
    "    winner = torch.load(genome_path)\n",
    "    net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "    #Initialize environment with rendering\n",
    "    env = DefendTheCenterNEAT(doomfinder('defend_the_center_modified.cfg'), render=True)\n",
    "\n",
    "    for episode in range(5):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            output = net.activate(obs)\n",
    "            action = np.argmax(output)\n",
    "            reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        print(f\"Episode {episode}: Total Reward = {total_reward}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "#Usage\n",
    "test_best_genome(\"neat-config.ini\", \"best_neat_genome.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
