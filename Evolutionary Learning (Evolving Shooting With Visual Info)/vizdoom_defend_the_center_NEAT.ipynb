{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a NEAT to learn defend_the_center.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from vizdoom import * #Import all of vizdoom\n",
    "import time #To make the program sleep (wait), so we can actually see what's happening\n",
    "from gymnasium import Env #Import OpenAI Gym's Env class\n",
    "from gymnasium.spaces import Discrete, Box #Import OpenAI Gym's Discrete and Box spaces\n",
    "import cv2 #OpenCV for image processing, used for modifying the DOOM environment to make it run faster \n",
    "from stable_baselines3.common.callbacks import BaseCallback #Import the BaseCallback class from stable_baselines3 to learn from the environment\n",
    "from stable_baselines3.common import env_checker #Import the env_checker class from stable_baselines3 to check the environment\n",
    "import os #To create directories for saving models\n",
    "import sys #To backtrack to root\n",
    "import neat\n",
    "\n",
    "original_sys_path = sys.path.copy() #Come back to this path later after we navigate to the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  #Add the parent directory to the path so we can import the pathfinder module\n",
    "from pathfinder import doomfinder, create_new_best_generation_directory, gamefinder #Import functions from the pathfinder module\n",
    "sys.path = original_sys_path #Set the path back to the original path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the VizDoom environment\n",
    "class DefendTheCenterNEAT:\n",
    "    def __init__(self, config_path, render=False):\n",
    "        self.game = DoomGame()\n",
    "        self.game.set_doom_game_path(gamefinder('DOOM2.wad'))\n",
    "        self.game.load_config(config_path)\n",
    "        self.game.set_window_visible(render)\n",
    "        self.game.init()\n",
    "\n",
    "    def get_observation(self):\n",
    "        state = self.game.get_state()\n",
    "        if state:\n",
    "            buffer = state.screen_buffer\n",
    "            grey = cv2.cvtColor(np.moveaxis(buffer, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grey, (40, 25), interpolation=cv2.INTER_CUBIC)\n",
    "            return resized.flatten()  #Flatten to 1000 elements for NEAT input\n",
    "        else:\n",
    "            return np.zeros(40 * 25)\n",
    "\n",
    "    def step(self, action):\n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 6) #Observe action every 6 frames, action will be repeated for 6 frames\n",
    "        done = self.game.is_episode_finished()\n",
    "        return reward, done\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        return self.get_observation()\n",
    "\n",
    "def eval_genome(genomes, config):\n",
    "    #Initialize the environment\n",
    "    env = DefendTheCenterNEAT(doomfinder('defend_the_center_modified.cfg'), render=False)\n",
    "\n",
    "    #Evaluate each genome in the population\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        fitness = 0\n",
    "\n",
    "        for _ in range(3):  #Evaluate over 3 episodes\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            episode_fitness = 0\n",
    "            ammo_wasted = 0\n",
    "            current_ammo = 26  #Initial ammo (adjust based on your config)\n",
    "\n",
    "            while not done:\n",
    "                #Get action from NEAT network\n",
    "                output = net.activate(obs)  # obs is a flattened array (4000 elements)\n",
    "                action = np.argmax(output)\n",
    "\n",
    "                #Take action\n",
    "                reward, done = env.step(action)\n",
    "                episode_fitness += reward\n",
    "\n",
    "                #Track ammo usage (optional penalty)\n",
    "                new_ammo = env.game.get_state().game_variables[0] if env.game.get_state() else current_ammo\n",
    "                ammo_used = current_ammo - new_ammo\n",
    "                if ammo_used > 0:\n",
    "                    ammo_wasted += ammo_used\n",
    "                current_ammo = new_ammo\n",
    "\n",
    "            #Penalize wasted ammo\n",
    "            episode_fitness -= ammo_wasted * 0.1\n",
    "            fitness += episode_fitness\n",
    "\n",
    "        #Assign fitness to the genome\n",
    "        genome.fitness = fitness / 3  #Average fitness across episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(winner, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_neat_genome.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mrun_neat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMaps and Configs/neat-config.ini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[49], line 14\u001b[0m, in \u001b[0;36mrun_neat\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m population\u001b[38;5;241m.\u001b[39madd_reporter(neat\u001b[38;5;241m.\u001b[39mStatisticsReporter())\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#Run evolution\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_genome\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Save the best genome\u001b[39;00m\n\u001b[0;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(winner, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_neat_genome.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\neat\\population.py:89\u001b[0m, in \u001b[0;36mPopulation.run\u001b[1;34m(self, fitness_function, n)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporters\u001b[38;5;241m.\u001b[39mstart_generation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Evaluate all genomes using the user-provided function.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[43mfitness_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miteritems\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Gather and report statistics.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 52\u001b[0m, in \u001b[0;36meval_genome\u001b[1;34m(genomes, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#Take action\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m reward, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m episode_fitness \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#Track ammo usage (optional penalty)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 22\u001b[0m, in \u001b[0;36mDefendTheCenterNEAT.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     21\u001b[0m     actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Observe action every 6 frames, action will be repeated for 6 frames\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mis_episode_finished()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reward, done\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_neat(config_path):\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_path)\n",
    "    \n",
    "    #Create population\n",
    "    population = neat.Population(config)\n",
    "\n",
    "    #Add reporters\n",
    "    population.add_reporter(neat.StdOutReporter(True))\n",
    "    population.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "    #Run evolution\n",
    "    winner = population.run(eval_genome)\n",
    "    #Save the best genome\n",
    "    torch.save(winner, \"best_neat_genome.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_neat(\"Maps and Configs/neat-config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_genome(config_path, genome_path):\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_path)\n",
    "    \n",
    "    #Load the best genome\n",
    "    winner = torch.load(genome_path)\n",
    "    net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "    #Initialize environment with rendering\n",
    "    env = DefendTheCenterNEAT(doomfinder('defend_the_center_modified.cfg'), render=True)\n",
    "\n",
    "    for episode in range(5):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            output = net.activate(obs)\n",
    "            action = np.argmax(output)\n",
    "            reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        print(f\"Episode {episode}: Total Reward = {total_reward}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "#Usage\n",
    "test_best_genome(\"neat-config.ini\", \"best_neat_genome.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
